{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Project Road Segmentation Using  Tensor Flow\n",
    "\n",
    "\n",
    "> We import the required python library for the homework below. Note that we have imported a python file(ourProjectFunctions) that contains some functions we would define ourselves. Those functions will be explained in the appropriate palces before it is to be used in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "import ourProjectFunctions     # Python Function file with the functions we will use in the project. \n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 666 # For the submission\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 800 images\n",
      "satImage_001.png\n",
      "Loading 800 images\n",
      "satImage_001.png\n"
     ]
    }
   ],
   "source": [
    "# Load a set of images\n",
    "root_dir = \"..\\\\training\\\\\"\n",
    "\n",
    "image_dir = root_dir + \"images_ext\\\\\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(10000, len(files)) # Load  100 images. \n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [ourProjectFunctions.load_image(image_dir + files[i], convert_lab=True) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth_ext\\\\\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [ourProjectFunctions.load_image(gt_dir + files[i]) for i in range(n)]\n",
    "print(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 400, 4)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "list_increased = list()\n",
    "\n",
    "for img in imgs:\n",
    "    \n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    dft = cv2.dft(gray_image, flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "    magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))\n",
    "    \n",
    "    img = np.append(img, magnitude_spectrum)\n",
    "    img = img.reshape([400, 400, 4])\n",
    "    list_increased.append(img)\n",
    "\n",
    "print(list_increased[0].shape)\n",
    "    \n",
    "imgs = list_increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth and shape of Satellite  images after patching and  Linearisation: \n",
      "(2000000, 8, 8, 4)\n",
      "lenth and shape of Ground truth  images after patching and Linearisation: \n",
      "(2000000, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "# Extract patches from input images\n",
    "patch_size = 8\n",
    "\n",
    "img_patches = [ourProjectFunctions.img_crop(imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "gt_patches = [ourProjectFunctions.img_crop(gt_imgs[i], patch_size, patch_size) for i in range(n)]\n",
    "\n",
    "X = np.asarray([img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))])\n",
    "gt_patches =  np.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "\n",
    "print (\"lenth and shape of Satellite  images after patching and  Linearisation: \")\n",
    "print(X.shape)\n",
    "print (\"lenth and shape of Ground truth  images after patching and Linearisation: \")\n",
    "print(gt_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = np.asarray([ourProjectFunctions.value_to_class_for_tensor_flow(np.mean(gt_patches[i])) for i in range(len(gt_patches))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images(1999800,8)\n",
      "validation_images(200,8)\n"
     ]
    }
   ],
   "source": [
    "#img_size=10;\n",
    "VALIDATION_SIZE = 200\n",
    "label_count = 2;\n",
    "validation_images = X[:VALIDATION_SIZE]\n",
    "validation_labels = Y[:VALIDATION_SIZE]\n",
    "\n",
    "train_images = X[VALIDATION_SIZE:]\n",
    "train_labels = Y[VALIDATION_SIZE:]\n",
    "\n",
    "\n",
    "print('train_images({0[0]},{0[1]})'.format(train_images.shape))\n",
    "print('validation_images({0[0]},{0[1]})'.format(validation_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1999800, 8, 8, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 8, 8, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_count = 2\n",
    "data_nodes = tf.placeholder('float', shape=[None, patch_size, patch_size, 4])\n",
    "label_nodes = tf.placeholder('float', shape=[None, labels_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1, seed=SEED)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4, 4, 32)\n"
     ]
    }
   ],
   "source": [
    "#conv layer 0 \n",
    "#W_conv0 = weight_variable([5, 5, 4, 32])\n",
    "#b_conv0 = bias_variable([32])\n",
    "\n",
    "#h_conv0 = tf.nn.relu6(tf.nn.bias_add(conv2d(data_nodes, W_conv0), b_conv0))\n",
    "#print (h_conv1.get_shape()) # => (40000, 28, 28, 32)\n",
    "#h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "# first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 4, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# (40000,784) => (40000,28,28,1)\n",
    "#image = tf.reshape(X, [-1,image_width , image_height,1])\n",
    "#print (image.get_shape()) # =>(40000,28,28,1)\n",
    "\n",
    "\n",
    "h_conv1 = tf.nn.relu6(tf.nn.bias_add(conv2d(data_nodes, W_conv1), b_conv1))\n",
    "#print (h_conv1.get_shape()) # => (40000, 28, 28, 32)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "print (h_pool1.get_shape()) # => (40000, 14, 14, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2, 2, 128)\n"
     ]
    }
   ],
   "source": [
    "#2nd convolution layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 128])\n",
    "b_conv2 = bias_variable([128])\n",
    "\n",
    "h_conv2 = tf.nn.relu6(tf.nn.bias_add(conv2d(h_pool1, W_conv2), b_conv2))\n",
    "#print (h_conv2.get_shape()) # => (128000, 14,14, 64)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "print (h_pool2.get_shape()) # => (1280000, 7, 7, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2048)\n"
     ]
    }
   ],
   "source": [
    "# densely connected layer\n",
    "W_fc1 = weight_variable([int(patch_size/4 * patch_size/4 * 128), 2048])\n",
    "b_fc1 = bias_variable([2048])\n",
    "\n",
    "# (40000, 7, 7, 64) => (40000, 3136)\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, int(patch_size/4 * patch_size/4 * 128)])\n",
    "\n",
    "h_fc1 = tf.nn.relu6(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "print (h_fc1.get_shape()) # => (40000, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder('float')\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# readout layer for deep net\n",
    "labels_count =2\n",
    "W_fc2 = weight_variable([2048, labels_count])\n",
    "b_fc2 = bias_variable([labels_count])\n",
    "\n",
    "y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# cost function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, label_nodes))\n",
    "\n",
    "regularizers = tf.nn.l2_loss(W_fc1) + tf.nn.l2_loss(b_fc1) + tf.nn.l2_loss(W_fc2) + tf.nn.l2_loss(b_fc2)\n",
    "\n",
    "# optimisation function\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy + 5e-6 * regularizers)\n",
    "# train_step = tf.train.MomentumOptimizer(0.001, 0.0).minimize(cross_entropy)\n",
    "# train_step = tf.train.AdadeltaOptimizer(learning_rate=0.01).minimize(cross_entropy)\n",
    "\n",
    "# evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y),1), tf.argmax(label_nodes,1))\n",
    "false_prediction = tf.logical_not(correct_prediction)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "true_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "false_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "true_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "false_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = tf.argmax(tf.nn.softmax(y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# set to 20000 on local environment to get 0.99 accuracy\n",
    "TRAINING_ITERATIONS = 200000\n",
    "    \n",
    "DROPOUT = 0.5\n",
    "#BATCH_SIZES = 200\n",
    "\n",
    "# set to 0 to train on all available data\n",
    "VALIDATION_SIZES = 2000\n",
    "BATCH_SIZE= 200\n",
    "\n",
    "# image number to output\n",
    "IMAGE_TO_DISPLAY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_images.shape[0]\n",
    "\n",
    "# serve data by batches\n",
    "def next_batch(batch_size):\n",
    "    \n",
    "    global train_images\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_images[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_validation_stats():\n",
    "    validation_accuracy = accuracy.eval(feed_dict={data_nodes: validation_images, \n",
    "                                                   label_nodes: validation_labels, \n",
    "                                                   keep_prob: 1.0})\n",
    "    print('validation_accuracy => %.4f'%validation_accuracy)\n",
    "    plt.plot(x_range, train_accuracies,'-b', label='Training acc')\n",
    "    plt.plot(x_range, validation_accuracies,'-g', label='Validation acc')\n",
    "    \n",
    "    plt.plot(x_range, f1_scores_train,'-y', label='Training F1')\n",
    "    plt.plot(x_range, f1_scores_test,'-r', label='Validation F1')\n",
    "    \n",
    "    \n",
    "    plt.legend(loc='lower right', frameon=False)\n",
    "    plt.ylim(ymax = 1.1, ymin = 0.0)\n",
    "   \n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('step')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_predictions():\n",
    "    # Load submission images\n",
    "    test_dir = '..\\\\test_set_images\\\\'\n",
    "    submission_dir = '..\\\\submission\\\\'\n",
    "    overlay_dir = '..\\\\submission_overlay\\\\'\n",
    "\n",
    "    if not os.path.isdir(submission_dir):\n",
    "        os.mkdir(submission_dir)\n",
    "\n",
    "    if not os.path.isdir(overlay_dir):\n",
    "        os.mkdir(overlay_dir)\n",
    "\n",
    "    files = os.listdir(test_dir)\n",
    "\n",
    "    for file in files:\n",
    "        img = ourProjectFunctions.load_image(test_dir + file + '\\\\' + file + '.png', convert_lab=True)\n",
    "        \n",
    "        gray_image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        dft = cv2.dft(gray_image, flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "        dft_shift = np.fft.fftshift(dft)\n",
    "        magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))\n",
    "\n",
    "        img = np.append(img, magnitude_spectrum)\n",
    "        img = img.reshape([608, 608, 4])\n",
    "\n",
    "        img_patches = ourProjectFunctions.img_crop(img, patch_size, patch_size)\n",
    "        X = np.array(img_patches)\n",
    "\n",
    "        prediction = sess.run(predict, feed_dict={ data_nodes: X, keep_prob: 1.0 })\n",
    "        img_prediction = ourProjectFunctions.label_to_img(608, 608, patch_size, patch_size, prediction)\n",
    "\n",
    "        img_overlay = ourProjectFunctions.make_img_overlay(img, img_prediction)\n",
    "\n",
    "        save_path = file + \".png\"\n",
    "        Image.fromarray(ourProjectFunctions.img_float_to_uint8(img_prediction)).save(submission_dir + save_path)\n",
    "        Image.fromarray(ourProjectFunctions.img_float_to_uint8(img_overlay)).save(overlay_dir + save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Saver to be able to restore a model\n",
    "saver = tf.train.Saver()\n",
    "save_dir = '..\\\\tmp\\\\'\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score train set =  0.07692307692306945 F1 Score test set =  0.18181818181816514\n",
      "training_accuracy / validation_accuracy => 0.04 / 0.10 for step 0\n",
      "F1 score train set =  0.05102040816325741 F1 Score test set =  0.18691588785045016\n",
      "training_accuracy / validation_accuracy => 0.07 / 0.13 for step 1\n",
      "F1 score train set =  0.0 F1 Score test set =  0.18181818181813905\n",
      "training_accuracy / validation_accuracy => 0.75 / 0.73 for step 2\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.90 for step 3\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.90 for step 4\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.90 for step 5\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.90 for step 6\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.90 for step 7\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.90 for step 8\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.90 for step 9\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.67 / 0.90 for step 10\n",
      "F1 score train set =  0.3333333333332803 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.84 for step 20\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.90 for step 30\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.92 / 0.90 for step 40\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.92 / 0.90 for step 50\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.82 / 0.90 for step 60\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.90 for step 70\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.90 for step 80\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.90 for step 90\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.92 / 0.90 for step 100\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.76 / 0.90 for step 200\n",
      "F1 score train set =  0.4639999999999542 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.67 / 0.77 for step 300\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.72 / 0.90 for step 400\n",
      "F1 score train set =  0.15999999999996672 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.89 / 0.89 for step 500\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.89 / 0.90 for step 600\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.90 for step 700\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.75 / 0.90 for step 800\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.92 / 0.88 for step 900\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.51 / 0.90 for step 1000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.90 / 0.89 for step 2000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 1.00 / 0.89 for step 3000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.80 / 0.89 for step 4000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.92 / 0.90 for step 5000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.83 / 0.90 for step 6000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.43 / 0.90 for step 7000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.79 / 0.90 for step 8000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.80 / 0.90 for step 9000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.73 / 0.90 for step 10000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.71 / 0.90 for step 20000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.82 / 0.90 for step 30000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.80 / 0.90 for step 40000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.75 / 0.90 for step 50000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.81 / 0.90 for step 60000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.77 / 0.90 for step 70000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.82 / 0.90 for step 80000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.81 / 0.90 for step 90000\n",
      "F1 score train set =  0.0 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.78 / 0.90 for step 100000\n",
      "F1 score train set =  0.03846153846153454 F1 Score test set =  0.0\n",
      "training_accuracy / validation_accuracy => 0.75 / 0.90 for step 199999\n",
      "validation_accuracy => 0.9000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAFyCAYAAADrieCVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21944095c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adan\\Documents\\EPFL\\PCML\\Segmentation\\Project_2\\ourProjectFunctions.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "f1_scores_train = []\n",
    "f1_scores_test = []\n",
    "x_range = []\n",
    "image_size = 400;\n",
    "\n",
    "display_step=1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(TRAINING_ITERATIONS):\n",
    "\n",
    "        #get new batch\n",
    "        batch_xs, batch_ys = next_batch(BATCH_SIZE)  \n",
    "\n",
    "\n",
    "        # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "        if i%display_step == 0 or (i+1) == TRAINING_ITERATIONS:\n",
    "\n",
    "            train_accuracy = accuracy.eval(feed_dict={data_nodes: batch_xs, \n",
    "                                                      label_nodes: batch_ys, \n",
    "                                                      keep_prob: 1.0})     \n",
    "            \n",
    "            tp_train = true_positives.eval(feed_dict={ data_nodes: batch_xs, \n",
    "                                                            label_nodes: batch_ys, \n",
    "                                                            keep_prob: 1.0})    \n",
    "\n",
    "            fp_train = false_positives.eval(feed_dict={ data_nodes: batch_xs, \n",
    "                                                    label_nodes: batch_ys, \n",
    "                                                    keep_prob: 1.0})   \n",
    "\n",
    "            fn_train = false_negatives.eval(feed_dict={ data_nodes: batch_xs, \n",
    "                                                    label_nodes: batch_ys, \n",
    "                                                    keep_prob: 1.0})  \n",
    "\n",
    "            precision_train = float(tp_train) / float(tp_train+fp_train + 0.0000000000001)\n",
    "            recall_train = float(tp_train) / float(tp_train + fn_train + 0.0000000000001)\n",
    "            F1_score_train = 2 * ( precision_train * recall_train ) / ( precision_train + recall_train + 0.0000000000001 )\n",
    "\n",
    "            \n",
    "            \n",
    "            if(VALIDATION_SIZE):\n",
    "                validation_accuracy = accuracy.eval(feed_dict={ data_nodes: validation_images, \n",
    "                                                                label_nodes: validation_labels, \n",
    "                                                                keep_prob: 1.0})     \n",
    "                \n",
    "                tp_test = true_positives.eval(feed_dict={ data_nodes: validation_images, \n",
    "                                                                label_nodes: validation_labels, \n",
    "                                                                keep_prob: 1.0})    \n",
    "\n",
    "                fp_test = false_positives.eval(feed_dict={ data_nodes: validation_images, \n",
    "                                                        label_nodes: validation_labels, \n",
    "                                                        keep_prob: 1.0})   \n",
    "            \n",
    "                fn_test = false_negatives.eval(feed_dict={ data_nodes: validation_images, \n",
    "                                                        label_nodes: validation_labels, \n",
    "                                                        keep_prob: 1.0})  \n",
    "\n",
    "                precision_test = float(tp_test) / float(tp_test+fp_test + 0.0000000000001)\n",
    "                recall_test = float(tp_test) / float(tp_test + fn_test + 0.0000000000001)\n",
    "                F1_score_test = 2 * ( precision_test * recall_test ) / ( precision_test + recall_test + 0.0000000000001 )\n",
    "                \n",
    "                \n",
    "                print(\"F1 score train set = \", F1_score_train,\"F1 Score test set = \", F1_score_test)\n",
    "                print('training_accuracy / validation_accuracy => %.2f / %.2f for step %d' % \n",
    "                (train_accuracy, validation_accuracy, i))\n",
    "\n",
    "                validation_accuracies.append(validation_accuracy)\n",
    "                f1_scores_train.append(F1_score_train)\n",
    "                f1_scores_test.append(F1_score_test)\n",
    "                \n",
    "            else:\n",
    "                 print('training_accuracy => %.4f for step %d'%(train_accuracy, i))\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            x_range.append(i)\n",
    "\n",
    "            # increase display_step\n",
    "            if i%(display_step*10) == 0 and i:\n",
    "                display_step *= 10\n",
    "        \n",
    "        # train on batch\n",
    "        sess.run(train_step, feed_dict={data_nodes: batch_xs, label_nodes: batch_ys, keep_prob: DROPOUT})\n",
    "        \n",
    "    display_validation_stats()\n",
    "    \n",
    "    generate_predictions()\n",
    "    \n",
    "    saver.save(sess, '..\\\\tmp\\\\model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "        generate_predictions()\n",
    "    else:\n",
    "        print('Oops, cannot load the model')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
